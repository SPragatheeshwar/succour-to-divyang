# succour-to-divyang
This is a project that focuses mainly on independent life style of the visually impaired people. 
It's been really difficult for them to walk on the streets independently because they don't know what is the obstacle is there in front of them.

This project helps them to identify the obstacles in front of them and tell the distance in which it is located. So that the user(visually imparied people) can
get a clear idea on the obstacle and dodge them.
They'll be intimated about the obstacle via voice commands.

flow of execution (user part):
**Part(I):**
(i) The user starts the applicaion and clicks a button in his bluetooth that will trigger the personal AI assistant that we've developed which will do
almost all the work.
(ii) Right now it's job is limited, so the user can use this assistant to open the object detection model to detect the obstacled in front of him.
(iii) User can also navigate himself to the nearby shop using the personal AI assistant, where we have used google API which will tell the directions and our system tells them about the obstacles.
**Part(II):**
(i) The previous part is for poor or econmically lower sections of people because now due to this corona almost 2/3rd of the india's population have phone and nowadays
phone processor are better than laptop processor.
(ii) This part is where the person will be using the camera but he'll be guided by an actual good sighted person via video call.
(iii) This also makes the elderly people feel less lonely and give them a boost in their mental health.
(iv) This is for society but coming to industrial uses companies can use this as an oppurnity to hire employees for their sales and marketing post,
because it's not that easy to speak to an unknown person. This shows their communication skills and shows their patients(calm) level.

(user's relative or caretaker part):
(i) The user's relative or caretaker can view the live locaion of the user and moniter him.
(ii) The user's relative will be able to send a message to the user.
(iii) The user's relative will be able to view the user's travel history.

snapshots:
(i) User's relative or caretaker UI:



<img width="684" alt="image" src="https://user-images.githubusercontent.com/102790803/161373722-168977f7-1e2b-4109-94fb-966ec0d53289.png">

<img width="925" alt="image" src="https://user-images.githubusercontent.com/102790803/161373761-3c76f035-8e28-4ecd-9ffa-f662fbd79bea.png">

(ii) Used Whatapp API to help the user's relative in any situation: 
<img width="925" alt="image" src="https://user-images.githubusercontent.com/102790803/161373780-cb5c49de-9bff-4d85-92b2-7fd488f7147c.png">

(iii)After selecting the person, you'll be directed to the payment page.
<img width="738" alt="image" src="https://user-images.githubusercontent.com/102790803/161373913-0e4cdd55-6bbd-493f-9df4-343e95165c78.png">


In part II:
The user part will look like:


<img width="471" alt="image" src="https://user-images.githubusercontent.com/102790803/161374424-11c25f0f-ef28-45f9-a996-348c381cf99c.png">


The helper's part look like:

<img width="473" alt="image" src="https://user-images.githubusercontent.com/102790803/161374449-3c6cbc11-a459-44f3-9848-875288d7ed5d.png">

<img width="488" alt="image" src="https://user-images.githubusercontent.com/102790803/161374467-9db2fe1b-9f07-454e-a9ea-8659b86d6123.png">


When one ends the call:

<img width="504" alt="image" src="https://user-images.githubusercontent.com/102790803/161374492-6d21428b-c6a0-4627-9ec0-e1be895285de.png">




